# Nova-Mind 成本分析报告

## 当前成本问题

### 1. LLM 调用成本（最高）

**后台认知循环**
- 频率：每 10 分钟一次
- 调用数：1 次 LLM 调用（生成想法/反思）
- 成本：每次 ~0.01-0.05 元（Manus 平台）
- 日成本：144 次 × 0.03 元 = 4.32 元/天

**创意生成任务**
- 频率：每 2 小时一次（后台）
- 调用数：1-3 次 LLM 调用（生成创意内容）
- 成本：每次 ~0.05-0.1 元
- 日成本：12 次 × 0.075 元 = 0.9 元/天

**用户对话**
- 频率：取决于用户输入
- 调用数：1 次 LLM 调用（Nova 回复）
- 成本：每次 ~0.01-0.05 元
- 估计日成本：50 次对话 × 0.03 元 = 1.5 元/天

**创意评论回应**
- 频率：每条评论一次
- 调用数：1 次 LLM 调用（生成回应）
- 成本：每次 ~0.01-0.03 元
- 估计日成本：10 次评论 × 0.02 元 = 0.2 元/天

**关系学习分析**
- 频率：每次对话后
- 调用数：1 次 LLM 调用（分析关系变化）
- 成本：每次 ~0.01-0.03 元
- 估计日成本：50 次对话 × 0.02 元 = 1 元/天

**当前日均 LLM 成本：~7.92 元/天 = 237 元/月**

### 2. 数据库查询成本

**高频查询**
- 身份恢复：每次对话 ~20 个查询
- 后台认知循环：每次 ~15 个查询
- 创意生成：每次 ~10 个查询
- 评论处理：每次 ~8 个查询

**问题**
- 重复查询相同数据（无缓存）
- 未优化的 JOIN 操作
- 缺少数据库索引
- 单条查询而不是批量操作

### 3. 重复调用问题

**相同问题的重复 LLM 调用**
- 用户问同样的问题 → 重复调用 LLM
- 后台循环生成相似想法 → 重复调用
- 没有缓存机制

**示例**
- 用户问"你是谁？" → LLM 调用
- 10 分钟后后台循环再问 → 又是 LLM 调用
- 结果相似但成本翻倍

## 优化机会

### 1. 智能缓存系统（预期节省 40%）

**LLM 响应缓存**
- 缓存相同问题的回答（24 小时有效期）
- 缓存概念提取结果（7 天有效期）
- 缓存关系分析结果（30 天有效期）
- 预期节省：40% 的 LLM 调用

**数据库查询缓存**
- 缓存用户档案（1 小时）
- 缓存概念图（6 小时）
- 缓存关系数据（12 小时）
- 预期节省：60% 的数据库查询

### 2. LLM 调用优化（预期节省 30%）

**批量调用**
- 合并多个小请求为一个大请求
- 示例：一次调用生成 5 个想法而不是 5 次调用
- 预期节省：20% 的 LLM 成本

**智能降级**
- 后台循环：从 10 分钟 → 20 分钟（降低 50%）
- 创意生成：从 2 小时 → 4 小时（降低 50%）
- 预期节省：10% 的 LLM 成本

### 3. 数据库查询优化（预期节省 50%）

**查询优化**
- 添加必要的数据库索引
- 优化 JOIN 操作
- 实现批量查询
- 预期节省：30% 的查询

**缓存策略**
- 使用内存缓存减少数据库访问
- 预期节省：20% 的查询

### 4. 本地模型备选方案（预期节省 70%）

**DeepSeek 集成**
- 对于简单任务使用 DeepSeek（成本 1/10）
- 对于复杂任务使用 Manus LLM
- 预期节省：70% 的 LLM 成本（针对简单任务）

## 优化目标

| 指标 | 当前 | 目标 | 节省比例 |
|------|------|------|---------|
| 日均 LLM 成本 | 7.92 元 | 3.17 元 | 60% |
| 月均 LLM 成本 | 237 元 | 95 元 | 60% |
| 数据库查询 | 100% | 50% | 50% |
| 总体成本 | 100% | 40% | 60% |

## 实施计划

### 第 1 周：智能缓存系统
- 实现多层缓存管理器
- 添加 LLM 响应缓存
- 添加数据库查询缓存

### 第 2 周：LLM 调用优化
- 实现批量调用
- 实现智能降级
- 添加成本估算

### 第 3 周：数据库优化
- 添加索引
- 优化查询
- 实现批量操作

### 第 4 周：监控和验证
- 创建成本监控仪表板
- 验证优化效果
- 调整策略

## 预期效果

✅ 将 Manus 平台的 API 成本从 237 元/月降低到 95 元/月
✅ 将数据库查询成本降低 50%
✅ 改善系统响应时间（缓存命中时）
✅ 提高系统稳定性（减少 API 调用频率）
✅ 为未来功能扩展留出成本空间
